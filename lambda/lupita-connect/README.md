# üöÄ Lupita Lambda v2.0.0 - AWS Connect + Bedrock + ElevenLabs

## ‚ö†Ô∏è CAMBIOS CR√çTICOS vs. Versi√≥n 1.0

| Par√°metro | v1.0 (ANTES) | v2.0 (AHORA) | Motivo |
|-----------|--------------|--------------|--------|
| `max_tokens` | **200** | **500** | 200 era muy limitado (~50 palabras). Imposible tener conversaciones naturales. |
| System Prompt | Simplificado | **Completo con 16 c√≥digos conductuales** | Migrado √≠ntegro de VAPI. Incluye t√©cnicas de conversaci√≥n y manejo de emociones. |
| Historial | ‚ùå No ten√≠a | **‚úÖ Implementado** | Lupita NO recordaba lo dicho hace 30 segundos. Ahora s√≠. |
| ElevenLabs | ‚ùå No integrado | **‚úÖ Integrado** | Mantiene la voz natural de Lupita (z1ngDYs2H24Xsd8ts3az). |

---

## üî¥ El Problema que Resolvimos

### Issue 1: max_tokens: 200
**S√≠ntoma:** Lupita solo pod√≠a decir ~50 palabras por respuesta.  
**Impacto:** Conversaciones rob√≥ticas, cortas, poco naturales.  
**Soluci√≥n:** Aumentado a 500 tokens (~125 palabras). Suficiente para respuestas emp√°ticas.

### Issue 2: System Prompt Simplificado
**S√≠ntoma:** Faltaban los 16 c√≥digos conductuales, t√©cnicas de conversaci√≥n, manejo de emociones.  
**Impacto:** Lupita no sab√≠a c√≥mo manejar llanto, soledad, confusi√≥n.  
**Soluci√≥n:** System prompt completo migrado de VAPI (800+ l√≠neas).

### Issue 3: Sin Historial
**S√≠ntoma:** Lupita no recordaba lo que el usuario dijo 30 segundos antes.  
**Impacto:** Conversaciones desconectadas, repetitivas.  
**Soluci√≥n:** Historial de conversaci√≥n implementado (√∫ltimos 20 turnos).

---

## üìã Requisitos Previos

1. **AWS Account** con acceso a Bedrock en us-west-2 (Oregon)
2. **Claude 3 Sonnet** habilitado en Bedrock Model Access
3. **ElevenLabs API Key** (obligatorio para voz)
4. **Voice ID de Lupita** (z1ngDYs2H24Xsd8ts3az)

---

## üîß Variables de Entorno (AWS Lambda Console)

```bash
ELEVENLABS_API_KEY=tu-api-key-de-elevenlabs
ELEVENLABS_VOICE_ID=z1ngDYs2H24Xsd8ts3az
```

### C√≥mo configurar:

1. AWS Lambda Console ‚Üí **lupita-voice-handler**
2. **Configuration** ‚Üí **Environment variables**
3. **Edit** ‚Üí **Add environment variable**
4. Agregar las dos variables arriba

---

## üöÄ Despliegue

### Paso 1: Instalar Dependencias

```bash
cd lambda/lupita-connect
npm install
```

### Paso 2: Crear ZIP de Deployment

```bash
zip -r lupita-lambda.zip  package.json node_modules/
```

### Paso 3: Subir a AWS Lambda

**Opci√≥n A: AWS CLI**
```bash
aws lambda update-function-code \
  --function-name lupita-voice-handler \
  --zip-file fileb://lupita-lambda.zip \
  --region us-west-2
```

**Opci√≥n B: AWS Console**
1. Lambda ‚Üí **lupita-voice-handler**
2. **Code** ‚Üí **Upload from** ‚Üí **.zip file**
3. Seleccionar `lupita-lambda.zip`

---

## üß™ Testing

### Test en AWS Console:

1. Lambda ‚Üí **lupita-voice-handler** ‚Üí **Test**
2. Crear evento de prueba:

```json
{
  "Details": {
    "ContactData": {
      "ContactId": "test-contact-123",
      "Attributes": {
        "userMessage": "Hola Lupita, buenos d√≠as. Me siento un poco sola hoy.",
        "userContext": "Usuario: Mar√≠a, 68 a√±os, vive sola en Guadalajara. Hijos en Los √Ångeles."
      }
    }
  }
}
```

3. Click **Test**

### Respuesta Esperada:

```json
{
  "statusCode": 200,
  "lupitaResponse": "¬°Hola Mar√≠a! Buenos d√≠as, ¬øc√≥mo amaneci√≥? La entiendo, a veces los d√≠as se ponen pesados cuando uno est√° solo. Pero aqu√≠ estoy yo para platicar con usted. Cu√©nteme, ¬øqu√© hizo ayer?",
  "audioBase64": "UklGRi4AAABXQVZFZm10IBAAAAABA...",
  "contactId": "test-contact-123",
  "metadata": {
    "tokensUsed": 89,
    "historyLength": 2
  }
}
```

**Notas:**
- `lupitaResponse`: Texto de Lupita (2-3 oraciones, natural)
- `audioBase64`: Audio MP3 generado por ElevenLabs (si configurado)
- `historyLength`: N√∫mero de turnos en la conversaci√≥n

---

## üìä Monitoreo

### Ver logs en tiempo real:

```bash
aws logs tail /aws/lambda/lupita-voice-handler --follow --region us-west-2
```

### En CloudWatch:
1. CloudWatch ‚Üí **Log groups**
2. Buscar `/aws/lambda/lupita-voice-handler`
3. Ver logs de invocaciones

---

## ‚ö° Notas T√©cnicas

### Sobre los 500 tokens:
- 200 tokens = ~50 palabras (muy corto)
- 500 tokens = ~125 palabras (suficiente para Lupita)
- Costo: ~$0.0015 por respuesta (Claude Sonnet)
- Total llamada 5 min: ~$0.015 (vs $0.070 con VAPI)

### Sobre el historial:
- Se guarda en memoria durante la llamada (Map en Lambda)
- L√≠mite: √∫ltimos 20 turnos (10 mensajes usuario + 10 respuestas)
- Se limpia autom√°ticamente con `cleanupHandler`
- **Para producci√≥n:** migrar a DynamoDB para persistencia

### Sobre ElevenLabs:
- Si NO configuras las variables de entorno, Lambda funciona igual pero sin audio
- Audio retornado en Base64 para AWS Connect
- Costo: ~$0.15 por 1,000 caracteres
- Modelo: `eleven_multilingual_v2` (optimizado para espa√±ol)

---

## üîÑ Arquitectura: VAPI vs AWS

```
ANTES (VAPI):
Llamada ‚Üí TELNYX ‚Üí VAPI ‚Üí Claude ‚Üí ElevenLabs ‚Üí Voz
                    ‚Üë
              (VAPI orquesta todo, $0.070/min)

AHORA (AWS):
Llamada ‚Üí Connect ‚Üí Lambda ‚Üí Bedrock ‚Üí ElevenLabs ‚Üí Voz
                     ‚Üë
              (Lambda orquesta, $0.003/min)
```

**Ahorro:** ~95% en costos de inferencia

---

## üìû Pr√≥ximos Pasos

1. ‚úÖ **Lambda creada con v2.0** (c√≥digo corregido)
2. ‚è≥ **Configurar variables de entorno** (ElevenLabs)
3. ‚è≥ **N√∫mero +52 M√©xico** (AWS Connect - Lunes)
4. ‚è≥ **Contact Flow** (flujo de llamadas)
5. ‚è≥ **Primera llamada de prueba completa**

---

## üö® Troubleshooting

### Error: "max_tokens must be between 1 and 4096"
**Causa:** Bedrock no acepta el par√°metro  
**Soluci√≥n:** Aseg√∫rate de usar v2.0.0 con `max_tokens: 500`

### Error: "ElevenLabs API error: 401"
**Causa:** API Key incorrecta  
**Soluci√≥n:** Verificar variable de entorno `ELEVENLABS_API_KEY`

### Error: "Context length exceeded"
**Causa:** Historial muy largo  
**Soluci√≥n:** Reducir l√≠mite de 20 a 10 turnos en l√≠nea 141

### Respuestas muy cortas (a√∫n con 500 tokens)
**Causa:** System prompt no aplicado correctamente  
**Soluci√≥n:** Verificar que `systemPromptWithContext` se pasa a Bedrock

---

## üìù Changelog

### v2.0.0 (25 Enero 2026)
- ‚úÖ `max_tokens` aumentado de 200 a 500
- ‚úÖ System prompt completo migrado de VAPI
- ‚úÖ Historial de conversaci√≥n implementado
- ‚úÖ Integraci√≥n ElevenLabs agregada
- ‚úÖ Funci√≥n `cleanupHandler` para limpiar memoria
- ‚úÖ Manejo de contexto de usuario
- ‚úÖ Error handling mejorado con respuesta de fallback

### v1.0.0 (23 Enero 2026)
- ‚úÖ Lambda b√°sica con Bedrock
- ‚ö†Ô∏è max_tokens: 200 (muy limitado)
- ‚ö†Ô∏è Sin historial
- ‚ö†Ô∏è Sin ElevenLabs

---

**Fecha:** 25 Enero 2026  
**Autor:** Claude + Fabiola Franco  
**Versi√≥n:** 2.0.0  
**Lanzamiento:** Lunes 27 Enero 2026
